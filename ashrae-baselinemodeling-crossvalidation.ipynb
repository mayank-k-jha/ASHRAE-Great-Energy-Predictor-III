{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Note: This notebook is intended for Kaggle Days meetup #4 Delhi.\n",
    "#### This is just a cleaned version of an awesome kernel https://www.kaggle.com/rohanrao/ashrae-half-and-half\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1 align=\"center\">ASHRAE - Great Energy Predictor III</h1>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<pre>\n",
    "In this competition, youâ€™ll develop accurate predictions of metered building energy usage in the following areas: <b>chilled water, electric, natural gas, \n",
    "hot water, and steam meters.</b> The data comes from over 1,000 buildings over a three-year timeframe. With better estimates of these energy-saving \n",
    "investments, large scale investors and financial institutions will be more inclined to invest in this area to enable progress in building efficiencies.\n",
    "</pre>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1 align=\"center\">Data</h1>\n",
    "<pre>\n",
    "Assessing the value of energy efficiency improvements can be challenging as there's no way to truly know how much energy a building would have used without \n",
    "the improvements. The best we can do is to build counterfactual models. Once a building is overhauled the new (lower) energy consumption is compared \n",
    "against modeled values for the original building to calculate the savings from the retrofit. More accurate models could support better market incentives \n",
    "and enable lower cost financing.\n",
    "\n",
    "This competition challenges you to build these counterfactual models across four energy types based on historic usage rates and observed weather. The \n",
    "dataset includes three years of hourly meter readings from over one thousand buildings at several different sites around the world.\n",
    "\n",
    "<b>train.csv: Main data consisting of target variable</b>\n",
    "<b>test.csv: Dataset for testing purpose</b>\n",
    "<b>building_meta.csv: Metadata consisting of additional information about building</b>\n",
    "<b>weather[train/test].csv: Weather data from a meteorological station as close as possible to the site</b>\n",
    "<b>sample_submission.csv: A valid sample submission</b>\n",
    "</pre>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing required libraries to proceed\n",
    "import gc\n",
    "import os\n",
    "import random\n",
    "import lightgbm as lgb\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from pandas.api.types import is_datetime64_any_dtype as is_datetime\n",
    "from pandas.api.types import is_categorical_dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/kaggle/input/ashrae-energy-prediction/sample_submission.csv\n",
      "/kaggle/input/ashrae-energy-prediction/building_metadata.csv\n",
      "/kaggle/input/ashrae-energy-prediction/weather_test.csv\n",
      "/kaggle/input/ashrae-energy-prediction/train.csv\n",
      "/kaggle/input/ashrae-energy-prediction/test.csv\n",
      "/kaggle/input/ashrae-energy-prediction/weather_train.csv\n"
     ]
    }
   ],
   "source": [
    "# Let's look where is our data in disk space\n",
    "for dirname, _, filenames in os.walk('/kaggle/input'):\n",
    "    for filename in filenames:\n",
    "        print(os.path.join(dirname, filename))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4>Dataset Compressor: Reducing size of our dataset to fit into our RAM</h4>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Memory optimization\n",
    "\n",
    "# Original code from https://www.kaggle.com/gemartin/load-data-reduce-memory-usage by @gemartin\n",
    "# Modified to support timestamp type, categorical type\n",
    "# Modified to add option to use float16\n",
    "\n",
    "def reduce_mem_usage(df, use_float16=True):\n",
    "    \"\"\"\n",
    "    Iterate through all the columns of a dataframe and modify the data type to reduce memory usage.        \n",
    "    \"\"\"\n",
    "    \n",
    "    start_mem = df.memory_usage().sum() / 1024**2\n",
    "    print(\"Memory usage of dataframe is {:.2f} MB\".format(start_mem))\n",
    "    \n",
    "    for col in df.columns:\n",
    "        if is_datetime(df[col]) or is_categorical_dtype(df[col]):\n",
    "            continue\n",
    "        col_type = df[col].dtype\n",
    "        \n",
    "        if col_type != object:\n",
    "            c_min = df[col].min()\n",
    "            c_max = df[col].max()\n",
    "            if str(col_type)[:3] == \"int\":\n",
    "                if c_min > np.iinfo(np.int8).min and c_max < np.iinfo(np.int8).max:\n",
    "                    df[col] = df[col].astype(np.int8)\n",
    "                elif c_min > np.iinfo(np.int16).min and c_max < np.iinfo(np.int16).max:\n",
    "                    df[col] = df[col].astype(np.int16)\n",
    "                elif c_min > np.iinfo(np.int32).min and c_max < np.iinfo(np.int32).max:\n",
    "                    df[col] = df[col].astype(np.int32)\n",
    "                elif c_min > np.iinfo(np.int64).min and c_max < np.iinfo(np.int64).max:\n",
    "                    df[col] = df[col].astype(np.int64)  \n",
    "            else:\n",
    "                if use_float16 and c_min > np.finfo(np.float16).min and c_max < np.finfo(np.float16).max:\n",
    "                    df[col] = df[col].astype(np.float16)\n",
    "                elif c_min > np.finfo(np.float32).min and c_max < np.finfo(np.float32).max:\n",
    "                    df[col] = df[col].astype(np.float32)\n",
    "                else:\n",
    "                    df[col] = df[col].astype(np.float64)\n",
    "        else:\n",
    "            df[col] = df[col].astype(\"category\")\n",
    "\n",
    "    end_mem = df.memory_usage().sum() / 1024**2\n",
    "    print(\"Memory usage after optimization is: {:.2f} MB\".format(end_mem))\n",
    "    print(\"Decreased by {:.1f}%\".format(100 * (start_mem - end_mem) / start_mem))\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading  /kaggle/input/ashrae-energy-prediction/sample_submission.csv\n",
      "Memory usage of dataframe is 636.26 MB\n",
      "Memory usage after optimization is: 198.83 MB\n",
      "Decreased by 68.7%\n",
      "Loading  /kaggle/input/ashrae-energy-prediction/building_metadata.csv\n",
      "Memory usage of dataframe is 0.07 MB\n",
      "Memory usage after optimization is: 0.02 MB\n",
      "Decreased by 73.8%\n",
      "Loading  /kaggle/input/ashrae-energy-prediction/weather_test.csv\n",
      "Memory usage of dataframe is 19.04 MB\n",
      "Memory usage after optimization is: 5.25 MB\n",
      "Decreased by 72.4%\n",
      "Loading  /kaggle/input/ashrae-energy-prediction/train.csv\n",
      "Memory usage of dataframe is 616.95 MB\n",
      "Memory usage after optimization is: 173.90 MB\n",
      "Decreased by 71.8%\n",
      "Loading  /kaggle/input/ashrae-energy-prediction/test.csv\n",
      "Memory usage of dataframe is 1272.51 MB\n",
      "Memory usage after optimization is: 358.65 MB\n",
      "Decreased by 71.8%\n",
      "Loading  /kaggle/input/ashrae-energy-prediction/weather_train.csv\n",
      "Memory usage of dataframe is 9.60 MB\n",
      "Memory usage after optimization is: 2.65 MB\n",
      "Decreased by 72.4%\n"
     ]
    }
   ],
   "source": [
    "# Let's load all of the data through our reducer\n",
    "# Dictionary which will contain all the dataset mapped with their name\n",
    "data = {}\n",
    "\n",
    "for dirname, _, filenames in os.walk('/kaggle/input'):\n",
    "    for filename in filenames:\n",
    "        print(\"Loading \", os.path.join(dirname, filename))\n",
    "        data[filename] = reduce_mem_usage(pd.read_csv(os.path.join(dirname, filename)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Small peek into Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>building_id</th>\n",
       "      <th>meter</th>\n",
       "      <th>timestamp</th>\n",
       "      <th>meter_reading</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2016-01-01 00:00:00</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2016-01-01 00:00:00</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2016-01-01 00:00:00</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>2016-01-01 00:00:00</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>2016-01-01 00:00:00</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   building_id  meter            timestamp  meter_reading\n",
       "0            0      0  2016-01-01 00:00:00            0.0\n",
       "1            1      0  2016-01-01 00:00:00            0.0\n",
       "2            2      0  2016-01-01 00:00:00            0.0\n",
       "3            3      0  2016-01-01 00:00:00            0.0\n",
       "4            4      0  2016-01-01 00:00:00            0.0"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[\"train.csv\"].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>row_id</th>\n",
       "      <th>building_id</th>\n",
       "      <th>meter</th>\n",
       "      <th>timestamp</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2017-01-01 00:00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2017-01-01 00:00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2017-01-01 00:00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>2017-01-01 00:00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>2017-01-01 00:00:00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   row_id  building_id  meter            timestamp\n",
       "0       0            0      0  2017-01-01 00:00:00\n",
       "1       1            1      0  2017-01-01 00:00:00\n",
       "2       2            2      0  2017-01-01 00:00:00\n",
       "3       3            3      0  2017-01-01 00:00:00\n",
       "4       4            4      0  2017-01-01 00:00:00"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[\"test.csv\"].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>site_id</th>\n",
       "      <th>building_id</th>\n",
       "      <th>primary_use</th>\n",
       "      <th>square_feet</th>\n",
       "      <th>year_built</th>\n",
       "      <th>floor_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Education</td>\n",
       "      <td>7432</td>\n",
       "      <td>2008.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>Education</td>\n",
       "      <td>2720</td>\n",
       "      <td>2004.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>Education</td>\n",
       "      <td>5376</td>\n",
       "      <td>1991.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Education</td>\n",
       "      <td>23685</td>\n",
       "      <td>2002.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>Education</td>\n",
       "      <td>116607</td>\n",
       "      <td>1975.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   site_id  building_id primary_use  square_feet  year_built  floor_count\n",
       "0        0            0   Education         7432      2008.0          NaN\n",
       "1        0            1   Education         2720      2004.0          NaN\n",
       "2        0            2   Education         5376      1991.0          NaN\n",
       "3        0            3   Education        23685      2002.0          NaN\n",
       "4        0            4   Education       116607      1975.0          NaN"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[\"building_metadata.csv\"].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>site_id</th>\n",
       "      <th>timestamp</th>\n",
       "      <th>air_temperature</th>\n",
       "      <th>cloud_coverage</th>\n",
       "      <th>dew_temperature</th>\n",
       "      <th>precip_depth_1_hr</th>\n",
       "      <th>sea_level_pressure</th>\n",
       "      <th>wind_direction</th>\n",
       "      <th>wind_speed</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>2016-01-01 00:00:00</td>\n",
       "      <td>25.000000</td>\n",
       "      <td>6.0</td>\n",
       "      <td>20.00000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1019.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>2016-01-01 01:00:00</td>\n",
       "      <td>24.406250</td>\n",
       "      <td>NaN</td>\n",
       "      <td>21.09375</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>1020.0</td>\n",
       "      <td>70.0</td>\n",
       "      <td>1.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>2016-01-01 02:00:00</td>\n",
       "      <td>22.796875</td>\n",
       "      <td>2.0</td>\n",
       "      <td>21.09375</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1020.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>2016-01-01 03:00:00</td>\n",
       "      <td>21.093750</td>\n",
       "      <td>2.0</td>\n",
       "      <td>20.59375</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1020.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>2016-01-01 04:00:00</td>\n",
       "      <td>20.000000</td>\n",
       "      <td>2.0</td>\n",
       "      <td>20.00000</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>1020.0</td>\n",
       "      <td>250.0</td>\n",
       "      <td>2.599609</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   site_id            timestamp  air_temperature  cloud_coverage  \\\n",
       "0        0  2016-01-01 00:00:00        25.000000             6.0   \n",
       "1        0  2016-01-01 01:00:00        24.406250             NaN   \n",
       "2        0  2016-01-01 02:00:00        22.796875             2.0   \n",
       "3        0  2016-01-01 03:00:00        21.093750             2.0   \n",
       "4        0  2016-01-01 04:00:00        20.000000             2.0   \n",
       "\n",
       "   dew_temperature  precip_depth_1_hr  sea_level_pressure  wind_direction  \\\n",
       "0         20.00000                NaN              1019.5             0.0   \n",
       "1         21.09375               -1.0              1020.0            70.0   \n",
       "2         21.09375                0.0              1020.0             0.0   \n",
       "3         20.59375                0.0              1020.0             0.0   \n",
       "4         20.00000               -1.0              1020.0           250.0   \n",
       "\n",
       "   wind_speed  \n",
       "0    0.000000  \n",
       "1    1.500000  \n",
       "2    0.000000  \n",
       "3    0.000000  \n",
       "4    2.599609  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[\"weather_train.csv\"].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>site_id</th>\n",
       "      <th>timestamp</th>\n",
       "      <th>air_temperature</th>\n",
       "      <th>cloud_coverage</th>\n",
       "      <th>dew_temperature</th>\n",
       "      <th>precip_depth_1_hr</th>\n",
       "      <th>sea_level_pressure</th>\n",
       "      <th>wind_direction</th>\n",
       "      <th>wind_speed</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>2017-01-01 00:00:00</td>\n",
       "      <td>17.796875</td>\n",
       "      <td>4.0</td>\n",
       "      <td>11.703125</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1021.5</td>\n",
       "      <td>100.0</td>\n",
       "      <td>3.599609</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>2017-01-01 01:00:00</td>\n",
       "      <td>17.796875</td>\n",
       "      <td>2.0</td>\n",
       "      <td>12.796875</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1022.0</td>\n",
       "      <td>130.0</td>\n",
       "      <td>3.099609</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>2017-01-01 02:00:00</td>\n",
       "      <td>16.093750</td>\n",
       "      <td>0.0</td>\n",
       "      <td>12.796875</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1022.0</td>\n",
       "      <td>140.0</td>\n",
       "      <td>3.099609</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>2017-01-01 03:00:00</td>\n",
       "      <td>17.203125</td>\n",
       "      <td>0.0</td>\n",
       "      <td>13.296875</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1022.0</td>\n",
       "      <td>140.0</td>\n",
       "      <td>3.099609</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>2017-01-01 04:00:00</td>\n",
       "      <td>16.703125</td>\n",
       "      <td>2.0</td>\n",
       "      <td>13.296875</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1022.5</td>\n",
       "      <td>130.0</td>\n",
       "      <td>2.599609</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   site_id            timestamp  air_temperature  cloud_coverage  \\\n",
       "0        0  2017-01-01 00:00:00        17.796875             4.0   \n",
       "1        0  2017-01-01 01:00:00        17.796875             2.0   \n",
       "2        0  2017-01-01 02:00:00        16.093750             0.0   \n",
       "3        0  2017-01-01 03:00:00        17.203125             0.0   \n",
       "4        0  2017-01-01 04:00:00        16.703125             2.0   \n",
       "\n",
       "   dew_temperature  precip_depth_1_hr  sea_level_pressure  wind_direction  \\\n",
       "0        11.703125                NaN              1021.5           100.0   \n",
       "1        12.796875                0.0              1022.0           130.0   \n",
       "2        12.796875                0.0              1022.0           140.0   \n",
       "3        13.296875                0.0              1022.0           140.0   \n",
       "4        13.296875                0.0              1022.5           130.0   \n",
       "\n",
       "   wind_speed  \n",
       "0    3.599609  \n",
       "1    3.099609  \n",
       "2    3.099609  \n",
       "3    3.099609  \n",
       "4    2.599609  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[\"weather_test.csv\"].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>row_id</th>\n",
       "      <th>meter_reading</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   row_id  meter_reading\n",
       "0       0              0\n",
       "1       1              0\n",
       "2       2              0\n",
       "3       3              0\n",
       "4       4              0"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[\"sample_submission.csv\"].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1 align=\"center\">Data Preprocessing and Cleaning</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
    "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a"
   },
   "outputs": [],
   "source": [
    "# ***Important***\n",
    "# Always set proper seed values before any experiments for reproducibility\n",
    "random.seed(2019)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's convert the non-numerical feature to numerical feature through LabelEncoder\n",
    "data[\"building_metadata.csv\"].loc[:, \"primary_use\"] = LabelEncoder().fit_transform(data[\"building_metadata.csv\"].loc[:, \"primary_use\"].values)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<pre>\n",
    "Now it's time to prepare data\n",
    "\n",
    "There are two files with features that need to be merged with the data. One is building metadata that has information on the buildings and the other is \n",
    "weather data that has information on the weather.\n",
    "\n",
    "Note that the only features created are hour, weekday and is_holiday!\n",
    "</pre>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# credits @Vopani\n",
    "\n",
    "def prepare_data(X, building_data, weather_data, test=False):\n",
    "    \"\"\"\n",
    "    Preparing final dataset with all features.\n",
    "    \"\"\"\n",
    "    \n",
    "    X = X.merge(building_data, on=\"building_id\", how=\"left\")\n",
    "    X = X.merge(weather_data, on=[\"site_id\", \"timestamp\"], how=\"left\")\n",
    "    \n",
    "    X.sort_values(\"timestamp\")\n",
    "    X.reset_index(drop=True)\n",
    "    \n",
    "    gc.collect()\n",
    "    \n",
    "    holidays = [\"2016-01-01\", \"2016-01-18\", \"2016-02-15\", \"2016-05-30\", \"2016-07-04\",\n",
    "                \"2016-09-05\", \"2016-10-10\", \"2016-11-11\", \"2016-11-24\", \"2016-12-26\",\n",
    "                \"2017-01-02\", \"2017-01-16\", \"2017-02-20\", \"2017-05-29\", \"2017-07-04\",\n",
    "                \"2017-09-04\", \"2017-10-09\", \"2017-11-10\", \"2017-11-23\", \"2017-12-25\",\n",
    "                \"2018-01-01\", \"2018-01-15\", \"2018-02-19\", \"2018-05-28\", \"2018-07-04\",\n",
    "                \"2018-09-03\", \"2018-10-08\", \"2018-11-12\", \"2018-11-22\", \"2018-12-25\",\n",
    "                \"2019-01-01\"]\n",
    "    \n",
    "    X.timestamp = pd.to_datetime(X.timestamp, format=\"%Y-%m-%d %H:%M:%S\")\n",
    "    X.square_feet = np.log1p(X.square_feet)\n",
    "    \n",
    "    X[\"hour\"] = X.timestamp.dt.hour\n",
    "    X[\"weekday\"] = X.timestamp.dt.weekday\n",
    "    X[\"is_holiday\"] = (X.timestamp.isin(holidays)).astype(int)\n",
    "    \n",
    "    drop_features = [\"timestamp\", \"sea_level_pressure\", \"wind_direction\", \"wind_speed\"]\n",
    "\n",
    "    X.drop(drop_features, axis=1, inplace=True)\n",
    "\n",
    "    if test:\n",
    "        row_ids = X.row_id\n",
    "        X.drop(\"row_id\", axis=1, inplace=True)\n",
    "        return X, row_ids\n",
    "    else:\n",
    "        y = np.log1p(X.meter_reading)\n",
    "        X.drop(\"meter_reading\", axis=1, inplace=True)\n",
    "        return X, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train, y_train = prepare_data(data[\"train.csv\"], data[\"building_metadata.csv\"], data[\"weather_train.csv\"])\n",
    "\n",
    "# Freeing up some memory by deleting uno more usable variables\n",
    "del data[\"train.csv\"], data[\"weather_train.csv\"]\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1 align=\"center\">Baseline Modeling with Cross Validation</h1>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Training Phase</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Building model with first half and validating on second half:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.6/site-packages/lightgbm/basic.py:1243: UserWarning: Using categorical_feature in Dataset.\n",
      "  warnings.warn('Using categorical_feature in Dataset.')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 300 rounds\n",
      "[200]\ttraining's rmse: 1.02788\tvalid_1's rmse: 1.37136\n",
      "[400]\ttraining's rmse: 0.91812\tvalid_1's rmse: 1.33719\n",
      "[600]\ttraining's rmse: 0.885171\tvalid_1's rmse: 1.33513\n",
      "[800]\ttraining's rmse: 0.866395\tvalid_1's rmse: 1.3342\n",
      "[1000]\ttraining's rmse: 0.852276\tvalid_1's rmse: 1.33625\n",
      "Early stopping, best iteration is:\n",
      "[752]\ttraining's rmse: 0.869987\tvalid_1's rmse: 1.33371\n",
      "Building model with second half and validating on first half:\n",
      "Training until validation scores don't improve for 300 rounds\n",
      "[200]\ttraining's rmse: 1.00517\tvalid_1's rmse: 1.53828\n",
      "[400]\ttraining's rmse: 0.90171\tvalid_1's rmse: 1.50549\n",
      "[600]\ttraining's rmse: 0.874264\tvalid_1's rmse: 1.50257\n",
      "[800]\ttraining's rmse: 0.85691\tvalid_1's rmse: 1.50153\n",
      "[1000]\ttraining's rmse: 0.844696\tvalid_1's rmse: 1.50154\n",
      "[1200]\ttraining's rmse: 0.835786\tvalid_1's rmse: 1.50284\n",
      "Early stopping, best iteration is:\n",
      "[985]\ttraining's rmse: 0.845938\tvalid_1's rmse: 1.50117\n"
     ]
    }
   ],
   "source": [
    "# Credits @Vopani\n",
    "\n",
    "X_half_1 = X_train[:int(X_train.shape[0] / 2)]\n",
    "X_half_2 = X_train[int(X_train.shape[0] / 2):]\n",
    "\n",
    "y_half_1 = y_train[:int(X_train.shape[0] / 2)]\n",
    "y_half_2 = y_train[int(X_train.shape[0] / 2):]\n",
    "\n",
    "categorical_features = [\"building_id\", \"site_id\", \"meter\", \"primary_use\", \"hour\", \"weekday\"]\n",
    "\n",
    "d_half_1 = lgb.Dataset(X_half_1, label=y_half_1, categorical_feature=categorical_features, free_raw_data=False)\n",
    "d_half_2 = lgb.Dataset(X_half_2, label=y_half_2, categorical_feature=categorical_features, free_raw_data=False)\n",
    "\n",
    "watchlist_1 = [d_half_1, d_half_2]\n",
    "watchlist_2 = [d_half_2, d_half_1]\n",
    "\n",
    "# https://lightgbm.readthedocs.io/en/latest/Parameters.html\n",
    "params = {\n",
    "    \"objective\": \"regression\",\n",
    "    \"boosting\": \"gbdt\",\n",
    "    \"num_leaves\": 40,\n",
    "    \"learning_rate\": 0.025,\n",
    "    \"feature_fraction\": 0.85,\n",
    "    \"reg_lambda\": 2,\n",
    "    \"metric\": \"rmse\"\n",
    "}\n",
    "\n",
    "print(\"Building model with first half and validating on second half:\")\n",
    "model_half_1 = lgb.train(params, train_set=d_half_1, num_boost_round=1400, valid_sets=watchlist_1, verbose_eval=200, early_stopping_rounds=300)\n",
    "\n",
    "print(\"Building model with second half and validating on first half:\")\n",
    "model_half_2 = lgb.train(params, train_set=d_half_2, num_boost_round=1400, valid_sets=watchlist_2, verbose_eval=200, early_stopping_rounds=300)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Testing Phase</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preparing test data with same features as train data.\n",
    "X_test, row_ids = prepare_data(data[\"test.csv\"], data[\"building_metadata.csv\"], data[\"weather_test.csv\"], test=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1 align=\"center\">Preparing Submission</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "12"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Getting prediction from our 1st Half trained model and weighting its prediction 0.5\n",
    "pred = np.expm1(model_half_1.predict(X_test, num_iteration=model_half_1.best_iteration)) / 2\n",
    "\n",
    "del model_half_1\n",
    "gc.collect()\n",
    "\n",
    "# Getting prediction from our 2nd Half trained model and weighting its prediction also 0.5\n",
    "pred += np.expm1(model_half_2.predict(X_test, num_iteration=model_half_2.best_iteration)) / 2\n",
    "    \n",
    "del model_half_2\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generating our submission file\n",
    "submission = pd.DataFrame({\"row_id\": row_ids, \"meter_reading\": np.clip(pred, 0, a_max=None)})\n",
    "submission.to_csv(\"submission.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
